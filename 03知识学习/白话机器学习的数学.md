
## 1.3 机器学习的算法
● 回归（regression）
回归就是在 处理**连续数据**如**时间序列数据**时使用的技术。

● 分类（classification）

● 聚类（clustering）


有监督学习：使用<mark style="background: #ADCCFFA6;">有标签</mark>的数据进行的学习
无监督学习：使用<mark style="background: #ADCCFFA6;">没有标签</mark>的数据进行学习


## 1.4 数学与编程

机器学习的算法  有 和统计方法类似的地方

# 第二章 学习回归 
## 基于广告费预测点击量

---
## 2.1 设置问题

机器就是从数据中学习，寻找某种规律

## 2.2 定义模型

点击量经常变化，点击量中含有噪声。所以函数不能完美通过所有的点

使用机器学习来找到模型参数的值
![[Pasted image 20230919151549.png]]


最小二乘法

### 2.3.1 最速下降法

在某个位置  要达到 最小值，通过求导来判断如何移动，
![[Pasted image 20230919152311.png]]

现在为了防止 减小陷入死循环，设置学习率、
![[Pasted image 20230919152406.png]]

![[Pasted image 20230919152531.png]]


## 多项式回归

也就是 把 函数的次数提升上去

## 2.5 多重回归
像这样包含了多个变量的回归称为多重回归
多个输入值，分别进行回归


![[Pasted image 20230919154249.png]]



![[Pasted image 20230919154402.png]]![[Pasted image 20230919154407.png]]

<mark style="background: #FFF3A3A6;">
计算量大、计算时间长是最速下降法的一个缺点。</mark>

## 2.6 随机梯度下降法

最速下降法，随机梯度下降法，两个都

![[Pasted image 20230919155747.png]]


![[Pasted image 20230919160013.png]]

小批量（mini-batch）梯度下降法。不管是随机梯度下降法还是小批量梯度下降法，我们都必须考虑

学习率 η。把 η 设置为合适的值是很重要的。



## 3.5 逻辑回归


决策边界

## 3.6 似然函数

## 3.7 对数似然函数